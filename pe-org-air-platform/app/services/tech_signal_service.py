import json
import logging
from typing import Dict, List, Optional
from datetime import datetime, timezone
from app.pipelines.job_signals import step4b_score_techstack
from app.pipelines.pipeline2_state import Pipeline2State
from app.services.s3_storage import get_s3_service
from app.repositories.company_repository import CompanyRepository
from app.repositories.signal_repository import get_signal_repository

logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s | %(levelname)-8s | %(message)s',
    datefmt='%H:%M:%S'
)
logger = logging.getLogger(__name__)


class TechSignalService:
    """Service to extract digital presence signals from tech stack analysis."""
    
    def __init__(self):
        self.s3_service = get_s3_service()
        self.company_repo = CompanyRepository()
        self.signal_repo = get_signal_repository()
    
    def analyze_company(self, ticker: str) -> Dict:
        """
        Analyze digital presence for a company and create digital_presence signals.
        Currently uses tech stack analysis from job postings.
        Could be extended with BuiltWith/SimilarTech APIs in the future.
        """
        ticker = ticker.upper()
        logger.info("=" * 60)
        logger.info(f"ðŸŽ¯ ANALYZING DIGITAL PRESENCE SIGNALS FOR: {ticker}")
        logger.info("=" * 60)
        
        # Get company from database
        company = self.company_repo.get_by_ticker(ticker)
        if not company:
            raise ValueError(f"Company not found: {ticker}")
        
        company_id = str(company['id'])
        company_name = company['name']
        logger.info(f"âœ… Found company: {company_name} (ID: {company_id})")
        
        # Delete existing digital_presence signals for fresh analysis
        deleted = self.signal_repo.delete_signals_by_category(company_id, "digital_presence")
        if deleted:
            logger.info(f"  ðŸ—‘ï¸ Deleted {deleted} existing digital_presence signals")
        
        # Note: For now, we use tech stack analysis from job postings
        # In the future, this could be extended with:
        # 1. BuiltWith API for technology stack analysis
        # 2. SimilarTech API for competitive analysis
        # 3. Website technology detection
        
        # For Phase 2, we'll use the tech stack scoring from job_signals pipeline
        # We need to run job collection first to get tech stack data
        logger.info("ðŸ“Š Running tech stack analysis from job postings...")
        
        # Create a minimal pipeline state for tech stack analysis
        # Note: In a real implementation, we would fetch job postings first
        # For now, we'll create a placeholder score based on company data
        # TODO: Integrate with actual job posting collection for tech stack analysis
        
        # Placeholder implementation - using company data to generate a score
        # This should be replaced with actual tech stack analysis
        techstack_score = self._calculate_digital_presence_score(company_name, ticker)
        
        # Create signal record
        self.signal_repo.create_signal(
            company_id=company_id,
            category="digital_presence",
            source="tech_stack_analysis",
            signal_date=datetime.now(timezone.utc),
            raw_value=f"Digital presence analysis: Tech stack score {techstack_score:.1f}/100",
            normalized_score=techstack_score,
            confidence=0.6,  # Medium confidence for placeholder implementation
            metadata={
                "techstack_score": techstack_score,
                "analysis_method": "job_postings_tech_stack",
                "notes": "Placeholder implementation - should be extended with BuiltWith/SimilarTech APIs",
                "company_name": company_name,
                "ticker": ticker
            }
        )
        
        # Update company signal summary
        logger.info("-" * 40)
        logger.info(f"ðŸ“Š Updating company signal summary...")
        self.signal_repo.upsert_summary(
            company_id=company_id,
            ticker=ticker,
            digital_score=techstack_score
        )
        
        # Summary
        logger.info("=" * 60)
        logger.info(f"ðŸ“Š DIGITAL PRESENCE ANALYSIS COMPLETE FOR: {ticker}")
        logger.info(f"   Tech Stack Score: {techstack_score:.1f}/100")
        logger.info(f"   Note: This is a placeholder implementation")
        logger.info(f"   Future: Integrate with BuiltWith/SimilarTech APIs")
        logger.info("=" * 60)
        
        return {
            "ticker": ticker,
            "company_id": company_id,
            "company_name": company_name,
            "normalized_score": round(techstack_score, 2),
            "confidence": 0.6,
            "breakdown": {
                "techstack_score": round(techstack_score, 1)
            },
            "analysis_method": "job_postings_tech_stack",
            "notes": "Placeholder - should be extended with BuiltWith/SimilarTech APIs"
        }
    
    def _calculate_digital_presence_score(self, company_name: str, ticker: str) -> float:
        """
        Calculate digital presence score based on company data.
        This is a placeholder implementation that should be replaced with:
        1. Actual tech stack analysis from job postings
        2. BuiltWith API integration
        3. SimilarTech API integration
        
        For now, returns a placeholder score based on company name/ticker.
        """
        # Placeholder logic - in real implementation, this would:
        # 1. Fetch job postings for the company
        # 2. Extract tech stack keywords using step4b_score_techstack()
        # 3. Calculate score based on modern tech stack presence
        
        # Simple placeholder: tech companies get higher scores
        tech_keywords = ["tech", "software", "digital", "cloud", "ai", "data"]
        company_lower = company_name.lower()
        
        # Check if company name contains tech-related keywords
        tech_indicator = any(keyword in company_lower for keyword in tech_keywords)
        
        # Base score with tech indicator bonus
        base_score = 50.0
        if tech_indicator:
            base_score += 20.0
        
        # Add some variation based on ticker (placeholder)
        ticker_hash = sum(ord(c) for c in ticker) % 100
        variation = (ticker_hash / 100.0) * 30.0
        
        final_score = min(100.0, base_score + variation)
        return round(final_score, 2)
    
    def analyze_all_companies(self) -> Dict:
        """Analyze digital presence signals for all target companies."""
        target_tickers = ["CAT", "DE", "UNH", "HCA", "ADP", "PAYX", "WMT", "TGT", "JPM", "GS"]
        
        logger.info("=" * 60)
        logger.info("ðŸŽ¯ ANALYZING DIGITAL PRESENCE SIGNALS FOR ALL COMPANIES")
        logger.info("=" * 60)
        
        results = []
        success_count = 0
        failed_count = 0
        
        for ticker in target_tickers:
            try:
                result = self.analyze_company(ticker)
                results.append({
                    "ticker": ticker,
                    "status": "success",
                    "score": result["normalized_score"],
                    "method": result["analysis_method"]
                })
                success_count += 1
            except Exception as e:
                logger.error(f"âŒ Failed to analyze {ticker}: {e}")
                results.append({
                    "ticker": ticker,
                    "status": "failed",
                    "error": str(e)
                })
                failed_count += 1
        
        logger.info("=" * 60)
        logger.info("ðŸ“Š ALL COMPANIES DIGITAL PRESENCE ANALYSIS COMPLETE")
        logger.info(f"   Successful: {success_count}")
        logger.info(f"   Failed: {failed_count}")
        logger.info(f"   Note: This is a placeholder implementation")
        logger.info(f"   Future: Integrate with BuiltWith/SimilarTech APIs")
        logger.info("=" * 60)
        
        return {
            "total_companies": len(target_tickers),
            "successful": success_count,
            "failed": failed_count,
            "results": results,
            "notes": "Placeholder implementation - should be extended with BuiltWith/SimilarTech APIs"
        }


# Singleton
_service: Optional[TechSignalService] = None

def get_tech_signal_service() -> TechSignalService:
    global _service
    if _service is None:
        _service = TechSignalService()
    return _service